{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tools for the agent  \n",
    "from langchain.agents import Tool  \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  \n",
    "from langchain.tools.render import render_text_description_and_args  \n",
    "from langchain.schema.runnable import RunnablePassthrough  \n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser  \n",
    "from langchain.agents.format_scratchpad import format_log_to_str  \n",
    "from langchain_openai import OpenAI  \n",
    "import os\n",
    "from langchain.agents import AgentExecutor\n",
    "from defineTool import vector_search_tool_func, web_search_tool_func, mcp_tool_func, create_tools\n",
    "from mcp_configs import mcp_configs     \n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain_mcp_tools import convert_mcp_to_langchain_tools\n",
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4102f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcb2f0",
   "metadata": {},
   "source": [
    "todo：换成deepseek的api key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba526f",
   "metadata": {},
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "Standard library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164a860",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    from langchain.chat_models import init_chat_model\n",
    "    from langchain.schema import HumanMessage\n",
    "    from langchain_ollama import ChatOllama\n",
    "    from langgraph.prebuilt import create_react_agent\n",
    "except ImportError as e:\n",
    "    print(f'\\nError: Required package not found: {e}')\n",
    "    print('Please ensure all required packages are installed\\n')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a18260",
   "metadata": {},
   "source": [
    "Local application imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c71e45",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# A very simple logger\n",
    "def init_logger() -> logging.Logger:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,  # logging.DEBUG,\n",
    "        format='\\x1b[90m[%(levelname)s]\\x1b[0m %(message)s'\n",
    "    )\n",
    "    return logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc615c16",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def run(query) -> None:\n",
    "    # Be sure to set ANTHROPIC_API_KEY and/or OPENAI_API_KEY as needed\n",
    "    load_dotenv()\n",
    "\n",
    "    # Check the api key early to avoid showing a confusing long trace\n",
    "    # if not os.environ.get('ANTHROPIC_API_KEY'):\n",
    "    #     raise Exception('ANTHROPIC_API_KEY env var needs to be set')\n",
    "    # if not os.environ.get('OPENAI_API_KEY'):\n",
    "    #     raise Exception('OPENAI_API_KEY env var needs to be set')\n",
    "\n",
    "    try:\n",
    "        # mcp_configs = {\n",
    "        #     \"tavily-mcp\": {\n",
    "        #         \"command\": \"npx\",\n",
    "        #         \"args\": [\"-y\", \"tavily-mcp@0.1.4\"],\n",
    "        #         \"env\": {\n",
    "        #             \"TAVILY_API_KEY\": os.environ[\"TAVILY_API_KEY\"],\n",
    "        #         },\n",
    "        #         \"disabled\": False,\n",
    "        #         \"autoApprove\": []\n",
    "        #     }\n",
    "        # }\n",
    "\n",
    "        mcptools, cleanup = await convert_mcp_to_langchain_tools(\n",
    "            mcp_configs,\n",
    "            init_logger()\n",
    "        )\n",
    "        # print(mcptools)\n",
    "        # tools = [  \n",
    "        #     vector_search_tool_func,\n",
    "        #     web_search_tool_func,\n",
    "        # ]\n",
    "        tools = create_tools()\n",
    "        tools.extend(mcptools)\n",
    "        model = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.environ[\"DS_API_KEY\"])  \n",
    "        \n",
    "        system_prompt = \"\"\"请尽可能以有帮助和准确的方式回应人类。你可以使用以下工具：{tools}。\n",
    "        始终首先尝试使用向量数据库搜索工具在向量数据库中搜索相关信息。如果向量数据库中不包含所需信息，再使用其他工具。\n",
    "        使用JSON对象通过提供action key（工具名称）和action_input key（工具输入）来指定工具。 \n",
    "        有效的“action”值包括：“Final Answer”或者{tool_names}。每个JSON对象只提供一个action。\"\"\"\n",
    "\n",
    "        # human prompt  \n",
    "        human_prompt = \"\"\"用户问题：{messages}。\n",
    "        注意：始终以JSON对象进行响应。\"\"\"\n",
    "\n",
    "        # create prompt template\n",
    "        # prompt = PromptTemplate.from_template(prompt_template)  \n",
    "        prompt = ChatPromptTemplate.from_messages(  \n",
    "            [  \n",
    "                (\"system\", system_prompt),  \n",
    "                (\"human\", human_prompt),  \n",
    "            ]  \n",
    "        )\n",
    "        prompt = prompt.partial(  \n",
    "            tools=render_text_description_and_args(list(tools)),  \n",
    "            tool_names=\", \".join([t.name for t in tools]),  \n",
    "        )\n",
    "\n",
    "        agent = create_react_agent(\n",
    "            model,\n",
    "            tools,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        # agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, return_intermediate_steps=True, handle_parsing_errors=True, verbose=True)\n",
    "\n",
    "        print('\\x1b[33m')  # color to yellow\n",
    "        print(query)\n",
    "        print('\\x1b[0m')   # reset the color\n",
    "        # messages = [HumanMessage(content=query)]\n",
    "        # result = await agent.ainvoke({\"messages\": messages})\n",
    "        result = await agent.invoke({\"messages\": query})\n",
    "        # the last message should be an AIMessage\n",
    "        response = result['messages'][-1].content\n",
    "        print('\\x1b[36m')  # color to cyan\n",
    "        print(result)\n",
    "        print(response)\n",
    "        print('\\x1b[0m')   # reset the color\n",
    "    finally:\n",
    "        if cleanup is not None:\n",
    "            await cleanup()\n",
    "def main(query) -> None:\n",
    "    asyncio.run(run(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(\"介绍一下DeepSeek\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
