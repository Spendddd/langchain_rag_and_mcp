{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e8eae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# create tool call for vector search and web search  \n",
    "from langchain.tools import tool  \n",
    "from langchain_mcp_tools import convert_mcp_to_langchain_tools\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.retrievers import MergerRetriever\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7070ff1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_tools():\n",
    "    \"\"\"创建工具\"\"\"\n",
    "    # 向量检索工具\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-zh-v1.5\", encode_kwargs={\"normalize_embeddings\": True})\n",
    "    retrieverList = []\n",
    "    collections=[\"LLMDoc\", \"LLMBook\"]\n",
    "    for collection in collections:\n",
    "        vectordb = Chroma(\n",
    "            persist_directory=\"./storage/chroma_db\",\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=collection\n",
    "        )\n",
    "        retriever = vectordb.as_retriever(search_kwargs={\"k\": 5}, search_type=\"similarity\", search_distance=\"cosine\", )\n",
    "        retrieverList.append(retriever)\n",
    "    \n",
    "    multi_retriever = MergerRetriever(retrievers=retrieverList)\n",
    "    vector_search_tool = create_retriever_tool(\n",
    "        name=\"VectorStoreSearch\",\n",
    "        description=\"用于检索向量数据库的工具\",\n",
    "        retriever=multi_retriever,\n",
    "        return_direct=True,\n",
    "    )\n",
    "    \n",
    "    # 网页检索工具\n",
    "    web_search_tool = TavilySearchResults(k=10)\n",
    "    # web_search_tool = create_retriever_tool(\n",
    "    #     name=\"WebSearch\",\n",
    "    #     description=\"用于检索网页的工具\",\n",
    "    #     retriever=web_search_tool_func,\n",
    "    #     return_direct=True,\n",
    "    # )\n",
    "    \n",
    "    # mcp协议检索工具\n",
    "    # mcp_tool = create_retriever_tool(\n",
    "    #     name=\"MCPWebSearchTool\",\n",
    "    #     description=\"用于通过mcp协议检索网页的工具\",\n",
    "    #     retriever=mcp_tool_func,\n",
    "    #     return_direct=True,\n",
    "    # )\n",
    "    \n",
    "    return [vector_search_tool, web_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2e592",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@tool  \n",
    "def vector_search_tool_func(query: str, llm) -> str:\n",
    "    \"\"\"用于检索向量数据库的工具\n",
    "    \n",
    "    Args:\n",
    "        query (str): 用户输入的问题\n",
    "        llm: LLM模型，用于检索\n",
    "    Returns:\n",
    "        str: 检索到的结果\n",
    "    \"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-zh-v1.5\", encode_kwargs={\"normalize_embeddings\": True})\n",
    "    retrieverList = []\n",
    "    collections=[\"LLMDoc\", \"LLMBook\"]\n",
    "    for collection in collections:\n",
    "        vectordb = Chroma(\n",
    "            persist_directory=\"./storage/chroma_db\",\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=collection\n",
    "        )\n",
    "        retriever = vectordb.as_retriever(search_kwargs={\"k\": 5}, search_type=\"similarity\", search_distance=\"cosine\", )\n",
    "        retrieverList.append(retriever)\n",
    "    \n",
    "    multi_retriever = MergerRetriever(retrievers=retrieverList)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=multi_retriever)  \n",
    "    return qa_chain.run(query) \n",
    "    # return tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6345bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search_tool_func(query: str) -> str:\n",
    "    \"\"\"用于检索网页的工具\n",
    "    Args:\n",
    "        query (str): 用户输入的问题\n",
    "    Returns:\n",
    "        str: 检索到的结果\n",
    "    \"\"\"\n",
    "    web_search_tool = TavilySearchResults(k=10)\n",
    "    return web_search_tool.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def mcp_tool_func() -> str:\n",
    "    \"\"\"用于通过mcp协议检索网页的工具\"\"\"\n",
    "    mcp_servers = {\n",
    "        \"tavily-mcp\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"-y\", \"tavily-mcp@0.1.4\"],\n",
    "            \"env\": {\n",
    "                \"TAVILY_API_KEY\": os.getenv[\"TAVILY_API_KEY\"],\n",
    "            },\n",
    "            \"disabled\": False,\n",
    "            \"autoApprove\": []\n",
    "        }\n",
    "    }\n",
    "    tools, cleanup = await convert_mcp_to_langchain_tools(\n",
    "        mcp_servers\n",
    "    )\n",
    "    return tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = ChatDeepSeek(model=\"deepseek-reasoner\", api_key=os.environ[\"DS_API_KEY\"])  \n",
    "\n",
    "    # 测试向量检索工具\n",
    "    vector_search_tool = vector_search_tool_func(\"你能告诉我关于深度学习的最新进展吗？\", model)\n",
    "    print(vector_search_tool)\n",
    "    \n",
    "    # 测试网页检索工具\n",
    "    web_search_tool = web_search_tool_func(\"你能告诉我关于深度学习的最新进展吗？\")\n",
    "    print(web_search_tool)\n",
    "    \n",
    "    # # 测试mcp协议检索工具\n",
    "    # mcp_tool = mcp_tool_func()\n",
    "    # print(mcp_tool)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
